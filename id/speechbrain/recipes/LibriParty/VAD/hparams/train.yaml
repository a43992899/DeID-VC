# ##################################################################################################
# Model: VAD on LibriParty with CRDNN.
# This code heavily relis on on-the-fly data augmentation using external data.
# Before running the code, please download the needed datasets:
#
# - LibriParty: https://drive.google.com/file/d/1--cAS5ePojMwNY5fewioXAv9YlYAWzIJ/view?usp=sharing
# - Musan: https://www.openslr.org/resources/17/musan.tar.gz
# - CommonLanguage: https://zenodo.org/record/5036977/files/CommonLanguage.tar.gz?download=1
#
# Authors: Mohamed Kleit 2021
#          Arjun V 2021
#          Mirco Ravanelli 2021
# ##################################################################################################

# Seed and output folders
seed: 1986
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref results/VAD_CRDNN/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt

# LibriParty (main data)
data_folder: !PLACEHOLDER  # e.g. /path/to/LibriParty

# Additional data (for augmentation)
open_rir_folder: !ref <data_folder> # where to store noisy +ris from open_rir
musan_folder: !PLACEHOLDER  # e.g, /path/to/musan (download it from the web before)
commonlanguage_folder: !PLACEHOLDER  # e.g, /path/to/commonlang (download it from the web before)

# Manifest files (created by the data preparation)
annotation_train: !ref <save_folder>/train.json
annotation_valid: !ref <save_folder>/valid.json
annotation_test: !ref <save_folder>/test.json
music_csv: !ref <save_folder>/music.csv
noise_csv: !ref <save_folder>/noise.csv
speech_csv: !ref <save_folder>/speech.csv
multilang_speech_csv: !ref <save_folder>/multilang_speech.csv
skip_prep: False # Skip data preparation

# Training parameters
N_epochs: 100
lr: 1.0
lr_final: 0.1
batch_size: 2
example_length: 5 # in seconds
sample_rate: 16000
time_resolution: 0.01 # in seconds
train_dataloader_opts:
    batch_size: !ref <batch_size>
valid_dataloader_opts:
    batch_size: !ref <batch_size>
test_dataloader_opts:
    batch_size: !ref <batch_size>

# Feature parameters
n_fft: 400
n_mels: 40

# Model parameters
activation: !name:torch.nn.LeakyReLU
dropout: 0.15
cnn_blocks: 2
cnn_channels: (16, 16)
cnn_kernelsize: (3, 3)
rnn_layers: 2
rnn_neurons: 32
rnn_bidirectional: True
dnn_blocks: 1
dnn_neurons: 16
output_neurons: 1


# Data augmentation
add_noise: !new:speechbrain.lobes.augment.EnvCorrupt
    openrir_folder: !ref <open_rir_folder>
    babble_prob: 0.0
    reverb_prob: 0.0
    noise_prob: 1.0
    noise_snr_low: -5
    noise_snr_high: -15

noise_corruption: !new:speechbrain.lobes.augment.EnvCorrupt
    openrir_folder: !ref <open_rir_folder>
    babble_prob: 0.0
    reverb_prob: 0.0
    noise_prob: 1.0
    noise_snr_low: 5
    noise_snr_high: 15

add_noise_musan: !new:speechbrain.lobes.augment.EnvCorrupt
    noise_csv: !ref <noise_csv>
    babble_prob: 0.0
    reverb_prob: 0.0
    noise_prob: 1.0
    noise_snr_low: -15
    noise_snr_high: -20

add_music_musan: !new:speechbrain.lobes.augment.EnvCorrupt
    noise_csv: !ref <music_csv>
    babble_prob: 0.0
    reverb_prob: 0.0
    noise_prob: 1.0
    noise_snr_low: -15
    noise_snr_high: -20

add_speech_musan: !new:speechbrain.lobes.augment.EnvCorrupt
    noise_csv: !ref <speech_csv>
    babble_prob: 0.0
    reverb_prob: 0.0
    noise_prob: 1.0
    noise_snr_low: -15
    noise_snr_high: -20

add_speech_multilang: !new:speechbrain.lobes.augment.EnvCorrupt
    noise_csv: !ref <multilang_speech_csv>
    babble_prob: 0.0
    reverb_prob: 0.0
    noise_prob: 1.0
    noise_snr_low: -15
    noise_snr_high: -20


# Models
compute_features: !new:speechbrain.lobes.features.Fbank
    sample_rate: !ref <sample_rate>
    n_fft: !ref <n_fft>
    n_mels: !ref <n_mels>
    hop_length: !ref <time_resolution> * 1000 # in ms

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: sentence

cnn: !new:speechbrain.nnet.containers.Sequential
    input_shape: [null, null, !ref <n_mels>]
    norm1: !name:speechbrain.nnet.normalization.LayerNorm
    cnn1: !name:speechbrain.lobes.models.CRDNN.CNN_Block
        channels: 16
        kernel_size: (3, 3)
    cnn2: !name:speechbrain.lobes.models.CRDNN.CNN_Block
        channels: 32
        kernel_size: (3, 3)

rnn: !new:speechbrain.nnet.RNN.GRU
    input_shape: [null, null, 320]
    hidden_size: !ref <rnn_neurons>
    num_layers: !ref <rnn_layers>
    bidirectional: True

dnn: !new:speechbrain.nnet.containers.Sequential
    input_shape: [null, null, !ref <rnn_neurons> * 2]
    dnn1: !name:speechbrain.lobes.models.CRDNN.DNN_Block
        neurons: !ref <dnn_neurons>
    dnn2: !name:speechbrain.lobes.models.CRDNN.DNN_Block
        neurons: !ref <dnn_neurons>
    lin: !name:speechbrain.nnet.linear.Linear
        n_neurons: !ref <output_neurons>
        bias: False


model: !new:torch.nn.ModuleList
    - [!ref <cnn>, !ref <rnn>, !ref <dnn>]

modules:
    model: !ref <model>
    cnn: !ref <cnn>
    rnn: !ref <rnn>
    dnn: !ref <dnn>
    mean_var_norm: !ref <mean_var_norm>

opt_class: !name:torch.optim.Adadelta
    lr: !ref <lr>
    rho: 0.95
    eps: 1.e-8

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <N_epochs>

lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler
    initial_value: !ref <lr>
    final_value: !ref <lr_final>
    epoch_count: !ref <N_epochs>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        model: !ref <model>
        normalizer: !ref <mean_var_norm>
        counter: !ref <epoch_counter>

compute_BCE_cost: !name:speechbrain.nnet.losses.bce_loss

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>

train_stats: !name:speechbrain.utils.metric_stats.BinaryMetricStats
test_stats: !name:speechbrain.utils.metric_stats.BinaryMetricStats
